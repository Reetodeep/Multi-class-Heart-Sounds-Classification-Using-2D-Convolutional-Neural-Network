# Multi-class-Heart-Sounds-Classification-Using-2D-Convolutional-Neural-Network
Heart disease is a major concern. To prevent this, it is important to detect cardiovascular diseases at the early stage. Early discovery of heart infections and constant treatment can lessen the death rate. However, the accurate and effective detection method of heart diseases is necessary to uncover this deadly threat at a very early stage, even without the presence of a medical professional. This paper studies the use of 2Dconvolutional neural network to classify heart sounds into normal and abnormal categories. The paper reports a classification of five designated categories of heart sounds such as artifact, extra heart sound, extra systole, murmur, and normal. For the betterment of the accuracy, we have reduced the number of convolutional neural network layers with a softmax layer at the top. Each convolutional layer is followed by a max pooling and a dropout layer which finally leads to a global average pooling layer. The proposed method achieves an accuracy of 83%.


In our proposed model, we used a simple stack of three convolution layers with a rectified linear circuit (ReLu) activation and followed by max-pooling layers. It is a low latency model with few layers and few filters per layer, alongside dropout. Max-pooling layers subsample the input image to reduce the computational load and the number of parameters. Dropout reduces the chances of overfitting, by randomly switching off some neurons in the network which is forces the data to find new paths. Hence both max-pooling and dropout layer reduces the chances of model overfitting. Dropout is the most popular regularization technique for deep neural networks. At the top, there are two fully connected layers. We used the features extracted from MFCCs in our proposed model. Here, input shape is (1, 40, 173) in the form of (sample height, sample width), with the 1 signifying that the images are grayscale. The activation function ReLu only defines the positive parts of the argument, as negative part of this function is zero. In our model, 2Ã—2 pooling kernel is taken with zero padding. Every neuron in pooling layer associated with the yields of predetermined number neurons of the past layer, situated in a receptive field. The maximum value from each receptive layer transfers to the next layer. The output of every convolution layer and max-pooling layer is of 3D shape (filters/channels, height, width). The width and height dimension shrinkes as we proceed deeper in the network. As the width and height shrink, we add more output channels in each convolutional layer. The last output tensor from the convolutional base (128, 20, 4) is fed to the dense layer to perfrom classification. Global average pooling function converts the 3D tensor to 1D tensor as dense model only takes vector of single dimension. In this layer, a tensor of dimension (128, 20, 4) is transformed to a vector of dimension (128). After passing through one dense layer, the desired output of dimension (5) is obtained. Since it is multiclass classification, we have used softmax activation. Adam optimizer is used to train the model as it adapts the learning rate as the training proceeds.

